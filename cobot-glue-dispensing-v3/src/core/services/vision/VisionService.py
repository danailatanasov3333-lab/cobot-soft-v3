import queue
import numpy as np

from modules import utils
from communication_layer.api.v1.topics import VisionTopics
from modules.VisionSystem.VisionSystem import VisionSystem
import os
import json
import cv2
import threading
from pathlib import Path
from modules.shared.MessageBroker import MessageBroker

PICKUP_AREA_CAMERA_TO_ROBOT_MATRIX_PATH = os.path.join(os.path.dirname(__file__), '..', '..', '..', 'VisionSystem',
                                                       'calibration', 'cameraCalibration', 'storage',
                                                       'calibration_result', 'pickupCamToRobotMatrix.npy')


class _VisionService(VisionSystem):
    """
        Vision service class for processing camera frames and detecting contours, workpieces, and ArUco markers.

    This class extends the VisionSystem and handles real-time frame processing, contour detection,
    filtering workpieces within a defined area, and interfacing with robot calibration and workpieces services.

    Attributes:
        MAX_QUEUE_SIZE (int): Maximum number of frames to store in the queue.
        frameQueue (queue.Queue): A queue to store the most recent frames for processing.
        contours (list): Detected contours in the current frame.
        workAreaCorners (dict): Coordinates defining the workpieces pickup area.
        filteredContours (list): Contours that are filtered based on the work area.
        drawOverlay (bool): Flag to determine whether to draw overlays on the frame.
        pickupCamToRobotMatrix (numpy.ndarray): Matrix to transform camera points to robot coordinates.

    """

    def __init__(self):
        """
            Initializes the VisionService with camera settings and prepares the frame queue and other attributes.

            This constructor initializes the camera service, the frame queue to store the latest frames,
            and loads the camera-to-robot matrix for transformation.

            Args:
                None
            """
        from core.application.ApplicationContext import get_core_settings_path

        # Get camera settings path from application context
        config_file_path = get_core_settings_path("camera_settings.json", create_if_missing=True)
        if config_file_path is None:
            # Fallback to hardcoded path for backward compatibility
            config_file_path = os.path.join(os.path.dirname(__file__), '..', '..', '..', 'backend', 'system', 'storage',
                                            'settings', 'camera_settings.json')
            print("VisionService: Warning - No application context set, using fallback camera settings path")

        # Check if the settings file exists, create with defaults if missing
        if not os.path.exists(config_file_path):
            print(f"VisionService: Camera settings file not found at {config_file_path}")
            print("VisionService: Creating default camera settings...")
            if not self._create_default_camera_settings(config_file_path):
                raise RuntimeError(f"Failed to create default camera settings at {config_file_path}")

        super().__init__(configFilePath=config_file_path)

        self.MAX_QUEUE_SIZE = 100  # Maximum number of frames to store in the queue
        self.frameQueue = queue.Queue(maxsize=self.MAX_QUEUE_SIZE)
        self.superRun = super().run
        self.latest_frame = None
        self.frame_lock = threading.Lock()

        self.contours = None
        self.workAreaCorners = None
        self.filteredContours = None
        self.pickupCamToRobotMatrix = self._loadPickupCamToRobotMatrix()
        broker = MessageBroker()
        broker.subscribe(VisionTopics.TRANSFORM_TO_CAMERA_POINT, self.transformRobotPointToCamera)

    @staticmethod
    def _get_default_camera_settings():
        """
        Returns the default camera settings configuration.

        Returns:
            dict: Default camera settings
        """
        return {
            "Index": 0,
            "Width": 1280,
            "Height": 720,
            "Skip frames": 30,
            "Capture position offset": 0,
            "Threshold": 100,
            "Threshold pickup area": 150,
            "Epsilon": 0.004,
            "Min contour area": 1000,
            "Max contour area": 10000000,
            "Contour detection": True,
            "Draw contours": False,
            "Preprocessing": {
                "Gaussian blur": True,
                "Blur kernel size": 5,
                "Threshold type": "binary_inv",
                "Dilate enabled": True,
                "Dilate kernel size": 3,
                "Dilate iterations": 2,
                "Erode enabled": True,
                "Erode kernel size": 3,
                "Erode iterations": 4
            },
            "Calibration": {
                "Chessboard width": 32,
                "Chessboard height": 20,
                "Square size (mm)": 25,
                "Skip frames": 30
            },
            "Brightness Control": {
                "Enable auto adjust": False,
                "Kp": 0.7,
                "Ki": 0.2,
                "Kd": 0.05,
                "Target brightness": 200
            },
            "Aruco": {
                "Enable detection": True,
                "Dictionary": "DICT_4X4_1000",
                "Flip image": False
            }
        }

    @staticmethod
    def _create_default_camera_settings(file_path):
        """
        Creates a camera settings file with default values.

        Args:
            file_path (str): Path where the settings file should be created

        Returns:
            bool: True if successful, False otherwise
        """
        try:
            # Ensure directory exists
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)

            # Get default settings
            default_settings = _VisionService._get_default_camera_settings()

            # Write to file
            with open(file_path, 'w') as f:
                json.dump(default_settings, f, indent=2)

            print(f"VisionService: Created default camera settings at {file_path}")
            return True

        except Exception as e:
            print(f"VisionService: Error creating default camera settings: {e}")
            return False

    def _loadPickupCamToRobotMatrix(self):
        """
             Loads the camera-to-robot transformation matrix from a predefined file.

             The matrix is required for transforming the camera coordinates to the robot's coordinate system.

             Returns:
                 numpy.ndarray or None: The transformation matrix if successful, otherwise None.
             """
        if not os.path.exists(PICKUP_AREA_CAMERA_TO_ROBOT_MATRIX_PATH):
            print(f"Error: Matrix file not found at {PICKUP_AREA_CAMERA_TO_ROBOT_MATRIX_PATH}")
            self.pickupCamToRobotMatrix = None
            # return None

        try:
            self.pickupCamToRobotMatrix = np.load(PICKUP_AREA_CAMERA_TO_ROBOT_MATRIX_PATH)
            # print("Matrix loaded:", self.pickupCamToRobotMatrix)
        except Exception as e:
            print(f"Error loading matrix: {e}")
            self.pickupCamToRobotMatrix = None

        return self.pickupCamToRobotMatrix

    def run(self):
        """
              Main loop that continuously processes frames from the camera.

              It detects contours, applies overlays if necessary, and processes workpieces within the defined work area.

              This method keeps running indefinitely, so it should be called in a separate thread or process.

              Returns:
                  None
              """
        print("Starting VisionService run loop...")
        broker = MessageBroker()
        last_publish_time = 0
        publish_interval = 1.0  # seconds)
        # if self.workAreaCorners is None:
        #     # print("No workAreaCorners found. Set them first.")
        #     pass

        while True:
            self.contours, frame, _ = super().run()
            if frame is None:
                continue

            with self.frame_lock:
                self.latest_frame = frame

    def getLatestFrame(self):
        """
            Retrieves the latest frame from the queue.

            Returns:
                numpy.ndarray or None: The most recent frame, or None if the queue is empty.
            """

        with self.frame_lock:
            if self.latest_frame is None:
                return None
            # convert to RGB before returning
            return cv2.cvtColor(self.latest_frame, cv2.COLOR_BGR2RGB)

        return frame

    def getContours(self):
        """
               Returns the detected contours from the most recent frame.

               Returns:
                   list: A list of contours detected in the most recent frame.
               """
        return self.contours

    def updateCameraSettings(self, settings: dict):
        """
             Updates the camera settings with the provided dictionary of settings.

             Args:
                 settings (dict): The new camera settings to apply.

             Returns:
                 bool: True if the settings were updated successfully, otherwise False.
             """
        return self.updateSettings(settings)

    def getFrameWidth(self):
        """
              Returns the width of the captured frame.

              Returns:
                  int: The width of the frame.
              """
        return self.frameHeight

    def getFrameHeight(self):
        """
               Returns the height of the captured frame.

               Returns:
                   int: The height of the frame.
               """
        return self.frameWidth

    def getCameraToRobotMatrix(self):
        """
              Returns the camera-to-robot transformation matrix.

              Returns:
                  numpy.ndarray or None: The matrix if successfully loaded, otherwise None.
              """
        return self.cameraToRobotMatrix

    def calibrateCamera(self):
        """
               Initiates the camera calibration process.

               Returns:
                   bool: Calibration result indicating success or failure.
               """
        result = super().calibrateCamera()
        print("Calibration result: ", result)
        return result

    def calibrate(self):
        """
        Backwards-compatible adapter: call calibrateCamera.
        Some controllers expect a `calibrate()` method on the service â€” forward to the implemented method.
        """
        return self.calibrateCamera()

    def setRawMode(self, rawMode: bool):
        """
                Sets the camera's raw mode, enabling or disabling it.

                Args:
                    rawMode (bool): True to enable raw mode, False to disable.
                """
        print("Setting raw mode to: ", rawMode)
        self.rawMode = rawMode

    def detectArucoMarkers(self, flip=False, image=None):
        """
              Detects ArUco markers in the provided image.

              Args:
                  flip (bool): If True, the image will be flipped before processing.
                  image (numpy.ndarray): The image in which to detect ArUco markers.

              Returns:
                  tuple: The detected ArUco marker corners, ids, and the processed image.
              """
        return super().detectArucoMarkers(flip, image)

    def captureImage(self):
        """
              Captures an image from the camera.

              Returns:
                  numpy.ndarray: The captured image.
              """
        image = super().captureImage()
        return image

    def detectQrCode(self):
        return super().detectQrCode()

    def stopContourDetection(self):
        self.contourDetection = False

    def startContourDetection(self):
        self.contourDetection = True

    def captureFrameThreadSafe(self):
        """
        Thread-safe method to capture a single frame using the camera lock.
        This prevents conflicts when multiple threads try to access camera frames.
        
        Returns:
            tuple: (contours, frame, filtered_contours) - same as superRun() but thread-safe
        """
        with self.frame_lock:
            print(f"Calling superRun() in thread {threading.current_thread().name}")
            return self.superRun()

    def transformRobotPointToCamera(self, message):
        # message format {"x": x, "y": y}
        x = message.get("x")
        y = message.get("y")
        point = (x, y)
        return utils.transformSinglePointToCamera(point, self.cameraToRobotMatrix)


class VisionServiceSingleton:
    """
        A Singleton class to manage a single instance of VisionService.

        This class ensures that only one instance of the VisionService is created and accessed globally.
        The `get_instance` method returns the same instance every time it is called.

        Methods:
            get_instance():
                Returns the single instance of the VisionService.
        """
    _visionServiceInstance = None  # Static variable to hold the instance

    @staticmethod
    def get_instance() -> _VisionService:
        """
               Returns the singleton instance of the VisionService.

               If the instance has not been created yet, it initializes the _VisionService class.

               Returns:
                   VisionService: The singleton instance of the VisionService.
               """
        if VisionServiceSingleton._visionServiceInstance is None:
            VisionServiceSingleton._visionServiceInstance = _VisionService()
        return VisionServiceSingleton._visionServiceInstance


if __name__ == "__main__":
    # Example usage
    import cv2

    vision_service = VisionServiceSingleton.get_instance()
    print("After instantiation, vision_service is: ", vision_service)

    import threading

    threading.Thread(target=vision_service.run,
                     daemon=True).start()  # This will start the camera processing loop in a new thread

    # You can call other methods like getLatestFrame, processContours, etc. as needed
    while True:
        image = vision_service.getLatestFrame()
        if image is not None:
            cv2.imshow("Latest Frame", image)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    # For example, to get the latest frame:
